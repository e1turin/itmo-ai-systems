# Отчет по Модулю 2. 
 # Лабораторная работа 1. Метод линейной регрессии
 ##
# Введение

 <!-- [Описание задачи и целей.] -->
Выдается датасет по варианту и нужно научиться предсказывать некоторые 
численные (непрерывные) величиныпо данному датасету. Для этого нужно
- предобработать данные и проанализировать их,
- разработать модель линейной регрессии,
- разработать предобработчик входных данных (скалер),
- применить разработанные модели и скалеры,
- проанализировать результаты.

### Описание метода

<!-- [Краткое описание метода линейной регрессии, его назначения и принципа работы.] -->
Суть метода линейной регрессии в том, чтобы апроксимировать некоторую
эмпирическую зависимость линейной функцией лучшим образом. 

Для этого нужно использовать некоторую метрику — удобнее всего подходит Метод
наименьших квадратов, т.е. сумма квадратов отклонения теоретической зависимости
от эмпирической по каждой точке.

Метрика минимизируется с помощью разных способов: итеративным умножением матриц,
градиентным спуском, градиентным стохастических спуском и пр.
Также можно для управления получаемыми весами можно использовать методы регуляризации.

### Псевдокод метода

<!-- [Здесь представлен псечвдокод алгоритма метода линейной регрессии.] -->
```py
class MyLinearRegression:
    def fit(X, y): Unit = save_weights((X^T • X)^{-1} • X^T • y)
    def predict(X) -> Array = X • get_weights()
```
### Результаты выполнения 

<!-- [Опишите полученные результаты после применения метода линейной регрессии.
Можете включить графики, численные значения и примеры.] -->
Результата оказались неплохими с учтом того, что явной линейной зависимости
между признаками не наблюдается. Выходит результат очень зависит от исследуемой
выборки. Так же стоит опасаться появления так называемой "авторегрессии" или
"автокорелляции", т.е. ситуации когда признак начинает коррелировать с
производным от него искусственно созданным признаком.

### Примеры использования метода

<!-- [Приведите примеры ситуаций, когда метод линейной регрессии может быть
полезен. Объясните, почему именно этот метод выбран.] -->
Метод может быть полезен, когда в исследуемой выборке наблюдается отчетливая
линейная зависимостю между признаками. Сферы применения: 
- предсказаняи физических величин
- простая *аналитика*

## Лабораторная работа 2. Метод k-ближайших соседей (k-NN)

### Введение

<!-- [Описание задачи и целей.] -->
Дан некоторый датасет, нужно научиться классифицировать элементы выборки по некоторому признаку, т.е. предсказывать некоторый категориальный признак. Для этого нужно
- обработать датасет и проанализировать его,
- реализовать модель k-ближайших соседей
- реализовать вычисления метрик (матрица ошибок)
- проверить работу классификатора

### Описание метода

Метод заключается в том, что для рассматриваемого элемента определяется ближайшие к нему другие, ранее рассмотренные (при обучении) элементы по какой-то определенной метрике, например, L2 норме.
<!-- [Краткое описание метода k-ближайших соседей, его назначения и принципа работы.] -->

### Псевдокод метода

```py
def most_common(l: list) = max(set(l), key=l.count)
def euclidean(point, data) = sqrt(sum((point - data)^{2}))

class KNeighborsClassifier:
    def fit(X, y) = saveX(X), savey(y)

    def predict(X) -> Array:
        for i, point in enumerate(X):
            distances = metric(point, getX())
            neighbors[i] = most_common(sorted(distances))
        return neighbors

    def evaluate(X, y) -> float:
        y_pred = predict(X)
        accuracy = sum(y_pred == y) / len(y)
        return accuracy
```
<!-- [Здесь представлен псевдокод алгоритма метода k-ближайших соседей.] -->
 ​
### Результаты выполнения 

Метод вполне хорошо работает несмотря даже на слабую разделяемость данных визуально. Величина метрики ROC AUC не превыщает 0.7 на данном датасете. 
<!-- [Опишите полученные результаты после применения метода k-ближайших соседей.
Можете включить графики, численные значения и примеры.] -->

### Примеры использования метода

Метод может использоваться тогда, когда элементы выборки хорошо сгруппированы, то есть в общем выполняется условие малого удаления элементов одного класса друг от друга (по выбранной метрике). Сферы применения:
- медицина,
- психология,
- политика возможно.
<!-- [Приведите примеры ситуаций, когда метод k-ближайших соседей может быть полезен.
Объясните, почему именно этот метод выбран.] -->

## Лабораторная работа 3. Деревья решений

### Введение


<!-- [Введение в тему лабораторной работы, описание задачи и целей.] -->

### Описание метода

[Краткое описание метода деревьев решений, его назначения и принципа работы.]

### Псевдокод метода

[Здесь представлен псевдокод алгоритма метода деревьев решений.]
 ​
### Результаты выполнения 

[Опишите полученные результаты после применения метода деревьев решений. Можете
включить графики, численные значения и примеры.]

### Примеры использования метода

[Приведите примеры ситуаций, когда метод деревьев решений может быть полезен.
Объясните, почему именно этот метод выбран.]

## Лабораторная работа 4. Логистическая регрессия

### Введение

[Описание задачи и целей.]

### Описание метода

[Краткое описание метода логистической регрессии, его назначения и принципа
работы.]

### Псевдокод метода

[Здесь представлен псевдокод алгоритма метода логистической регрессии.]
 ​
### Результаты выполнения 

[Опишите полученные результаты после применения метода логистической регрессии.
Можете включить графики, численные значения и примеры.]

### Примеры использования метода

[Приведите примеры ситуаций, когда метод логистической регрессии может быть
полезен. Объясните, почему именно этот метод выбран.]

## Сравнение методов

### Сравнительный анализ методов

[Произведите сравнительный анализ результатов и производительности каждого
метода. Опишите их преимущества и ограничения.]

### Примеры лучшего использования каждого метода

[Укажите, в каких ситуациях каждый из методов наиболее эффективен и почему.]

## Заключение

[Окончательные выводы и обобщение результатов.]

## Приложения

Весь код используемый при выполнении лабораторных работ представлен в личном
репозитории на платформе GitHub:
 - https://github.com/e1turin/itmo-ai-systems 